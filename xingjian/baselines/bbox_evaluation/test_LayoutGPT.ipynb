{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/viscam/projects/ns-diffusion/xingjian/miniconda3/envs/diffusion/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import random\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import wandb\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from dataset_clevr_ryan import RelationalDataset, BoundingBox\n",
    "from utils import *\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from einops import rearrange, reduce\n",
    "from einops.layers.torch import Rearrange\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/viscam/projects/ns-diffusion/ryan/LayoutGPT-master/llm_output/counting/clevr2O__gpt4-chat_layoutGPT_eval_adjusted.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m address5 \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/viscam/projects/ns-diffusion/ryan/LayoutGPT-master/llm_output/counting/clevr5O__gpt4-chat_layoutGPT_eval_adjusted.pkl\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m address8 \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/viscam/projects/ns-diffusion/ryan/LayoutGPT-master/llm_output/counting/clevr8O__gpt4-chat_layoutGPT_eval_adjusted.pkl\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> 7\u001b[0m result2 \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mload(\u001b[39mopen\u001b[39;49m(address2, \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[1;32m      8\u001b[0m result3 \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mload(\u001b[39mopen\u001b[39m(address3, \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m      9\u001b[0m result4 \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mload(\u001b[39mopen\u001b[39m(address4, \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m))\n",
      "File \u001b[0;32m/viscam/projects/ns-diffusion/xingjian/miniconda3/envs/diffusion/lib/python3.10/site-packages/IPython/core/interactiveshell.py:282\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[1;32m    276\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    277\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    279\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m     )\n\u001b[0;32m--> 282\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/viscam/projects/ns-diffusion/ryan/LayoutGPT-master/llm_output/counting/clevr2O__gpt4-chat_layoutGPT_eval_adjusted.pkl'"
     ]
    }
   ],
   "source": [
    "# pickle load from address\n",
    "address2 = \"/viscam/projects/ns-diffusion/ryan/LayoutGPT-master/llm_output/counting/clevr2O__gpt4-chat_layoutGPT_eval_adjusted.pkl\"\n",
    "address3 = \"/viscam/projects/ns-diffusion/ryan/LayoutGPT-master/llm_output/counting/clevr3O__gpt4-chat_layoutGPT_eval_adjusted.pkl\"\n",
    "address4 = \"/viscam/projects/ns-diffusion/ryan/LayoutGPT-master/llm_output/counting/clevr4O__gpt4-chat_layoutGPT_eval_adjusted.pkl\"\n",
    "address5 = \"/viscam/projects/ns-diffusion/ryan/LayoutGPT-master/llm_output/counting/clevr5O__gpt4-chat_layoutGPT_eval_adjusted.pkl\"\n",
    "address8 = \"/viscam/projects/ns-diffusion/ryan/LayoutGPT-master/llm_output/counting/clevr8O__gpt4-chat_layoutGPT_eval_adjusted.pkl\"\n",
    "result2 = pickle.load(open(address2, \"rb\"))\n",
    "result3 = pickle.load(open(address3, \"rb\"))\n",
    "result4 = pickle.load(open(address4, \"rb\"))\n",
    "result5 = pickle.load(open(address5, \"rb\"))\n",
    "result8 = pickle.load(open(address8, \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../bbox_classifier')\n",
    "from classifier import BboxClassifier\n",
    "from eval_pipeline import *\n",
    "metric_model = BboxClassifier()\n",
    "metric_model.load_state_dict(torch.load('../bbox_classifier/4-layer-DNN-48_multi_rels-400.pth'))\n",
    "def single_image_eval(bboxes, relations, relations_ids, eval_info = EvalInfo()):\n",
    "    # print(\"entered single image eval\")\n",
    "    # print(f\"inputs: {bboxes}, {relations}, {relations_ids}\")\n",
    "    correct_relations = 0\n",
    "    for (i, rel) in enumerate(relations):\n",
    "        (a, b) = relations_ids[i]\n",
    "        a = a.item()\n",
    "        b = b.item()\n",
    "        # print(\"?\", bboxes[a],bboxes[b], rel)\n",
    "        rel_id = rel[-1]\n",
    "        input = torch.concat([bboxes[a].cuda(), bboxes[b].cuda(), torch.tensor([rel_id]).cuda()])\n",
    "        input = input.cuda()\n",
    "        metric_model.cuda()\n",
    "        pred = metric_model(input)[0].item()\n",
    "        correct_relations += pred > 0.5\n",
    "        eval_info.update(rel_id, pred > 0.5)\n",
    "\n",
    "        # print(f\"{i}th relation: {pred} vs {rel[0]}\")\n",
    "    return correct_relations / len(relations), eval_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(data, obj_num, wandb_drawer = None):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    metric_model.to(device)\n",
    "    metric_model.eval()\n",
    "    all_gt_bboxes, all_gen_bboxes, all_relations, all_relation_ids = data\n",
    "\n",
    "    size = len(all_gt_bboxes)\n",
    "    assert size == 100\n",
    "\n",
    "    eval_info = EvalInfo()\n",
    "    scores = []\n",
    "\n",
    "    all_gen_bboxes = all_gen_bboxes / 64 - 1\n",
    "\n",
    "    for i in range(size):\n",
    "        bboxes = all_gen_bboxes[i]\n",
    "        relations = all_relations[i]\n",
    "        relations_ids = all_relation_ids[i]\n",
    "        if i == 0:\n",
    "            print(\"bboxes\", bboxes)\n",
    "        score, eval_info = single_image_eval(bboxes, relations, relations_ids, eval_info)\n",
    "        scores.append(score)\n",
    "    \n",
    "    bboxes = [[BoundingBox(e.tolist()) for e in bboxes] for bboxes in all_gen_bboxes]\n",
    "\n",
    "    images = [None] * size\n",
    "    for i in range(size):\n",
    "        image = Image.new('RGB', (256, 256), (255, 255, 255))\n",
    "        colours = [(255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 0), (0, 255, 255), (255, 0, 255)] # red, green, blue, yellow, cyan, magenta\n",
    "        for j, bbox in enumerate(bboxes[i]):\n",
    "            image = bbox.draw(image, color=colours[j % len(colours)])\n",
    "        images[i] = image\n",
    "    if wandb_drawer is not None:\n",
    "        wandb_drawer.log({\"images\": [wandb.Image(image) for image in images]}, step = obj_num)\n",
    "    # save images to file\n",
    "    for i in range(size):\n",
    "        images[i].save(f\"images/LayoutGPT_{obj_num}_{i}.png\")\n",
    "\n",
    "    avg_score = sum(scores) / len(scores)\n",
    "    \n",
    "\n",
    "    # separately log each relation's acc\n",
    "    eval_info_list = eval_info.to_list()\n",
    "    eval_info.print()\n",
    "    for i in range(6):\n",
    "        print(f\"acc_{eval_info.relation_names[i]}: {eval_info_list[i]}\")\n",
    "        if wandb_drawer is not None:\n",
    "            wandb_drawer.log({f\"acc_{eval_info.relation_names[i]}\": eval_info_list[i]}, step = obj_num)\n",
    "    print(f\"avg_acc: {avg_score}\")\n",
    "    if wandb_drawer is not None:\n",
    "        wandb_drawer.log({\"acc\": avg_score}, step = obj_num)\n",
    "    return avg_score\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mxingjian-bai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/viscam/projects/ns-diffusion/xingjian/baselines/cfg_bbox7_cleanup/wandb/run-20230720_111519-wcpfyapl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/xingjian-bai/diffusion_bbox_eval/runs/wcpfyapl' target=\"_blank\">LayoutGPT_3</a></strong> to <a href='https://wandb.ai/xingjian-bai/diffusion_bbox_eval' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/xingjian-bai/diffusion_bbox_eval' target=\"_blank\">https://wandb.ai/xingjian-bai/diffusion_bbox_eval</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/xingjian-bai/diffusion_bbox_eval/runs/wcpfyapl' target=\"_blank\">https://wandb.ai/xingjian-bai/diffusion_bbox_eval/runs/wcpfyapl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bboxes tensor([[-0.6406,  0.0000, -0.5000, -0.4688],\n",
      "        [-0.1406,  0.0000, -0.6719, -0.6562]])\n",
      "left: 90 / 99\n",
      "right: 90 / 99\n",
      "front: 50 / 99\n",
      "behind: 58 / 99\n",
      "above: 0 / 1\n",
      "below: 0 / 1\n",
      "acc_left: 0.9090909090909091\n",
      "acc_right: 0.9090909090909091\n",
      "acc_front: 0.5050505050505051\n",
      "acc_behind: 0.5858585858585859\n",
      "acc_above: 0.0\n",
      "acc_below: 0.0\n",
      "avg_acc: 0.7272727272727273\n",
      "bboxes tensor([[ 0.0312, -0.2344, -0.0312, -0.5781],\n",
      "        [-0.5625, -0.2344, -0.7656, -0.6562],\n",
      "        [-0.2812, -0.2812, -0.3125, -0.3750]])\n",
      "left: 205 / 296\n",
      "right: 203 / 296\n",
      "front: 73 / 296\n",
      "behind: 217 / 296\n",
      "above: 1 / 4\n",
      "below: 0 / 4\n",
      "acc_left: 0.6925675675675675\n",
      "acc_right: 0.6858108108108109\n",
      "acc_front: 0.24662162162162163\n",
      "acc_behind: 0.7331081081081081\n",
      "acc_above: 0.25\n",
      "acc_below: 0.0\n",
      "avg_acc: 0.589527027027027\n",
      "bboxes tensor([[-0.0625,  0.0781, -0.4688, -0.4062],\n",
      "        [ 0.4688, -0.1562, -0.4688, -0.4844],\n",
      "        [-0.6875, -0.0312, -0.4688, -0.4219],\n",
      "        [ 0.3125, -0.6406, -0.5000, -0.5000]])\n",
      "left: 377 / 581\n",
      "right: 382 / 581\n",
      "front: 265 / 581\n",
      "behind: 353 / 581\n",
      "above: 0 / 19\n",
      "below: 0 / 19\n",
      "acc_left: 0.648881239242685\n",
      "acc_right: 0.657487091222031\n",
      "acc_front: 0.45611015490533563\n",
      "acc_behind: 0.6075731497418244\n",
      "acc_above: 0.0\n",
      "acc_below: 0.0\n",
      "avg_acc: 0.592512908777969\n",
      "bboxes tensor([[ 0.4844, -0.0781, -0.5000, -0.4531],\n",
      "        [-0.1562, -0.2500, -0.6719, -0.6406],\n",
      "        [-0.5938, -0.2031, -0.5781, -0.5469],\n",
      "        [ 0.8281, -0.0938, -0.6719, -0.4688],\n",
      "        [-0.4531,  0.0469, -0.4219, -0.3906]])\n",
      "left: 551 / 939\n",
      "right: 561 / 939\n",
      "front: 339 / 939\n",
      "behind: 476 / 939\n",
      "above: 0 / 61\n",
      "below: 0 / 61\n",
      "acc_left: 0.5867944621938233\n",
      "acc_right: 0.597444089456869\n",
      "acc_front: 0.3610223642172524\n",
      "acc_behind: 0.5069222577209798\n",
      "acc_above: 0.0\n",
      "acc_below: 0.0\n",
      "avg_acc: 0.5130457933972311\n",
      "bboxes tensor([[-0.4219,  0.3750, -0.5312, -0.4688],\n",
      "        [ 0.1562, -0.0156, -0.4688, -0.4219],\n",
      "        [-0.7812, -0.0625, -0.6719, -0.6406],\n",
      "        [ 0.6250, -0.0781, -0.4531, -0.4375],\n",
      "        [-0.2031, -0.0469, -0.6406, -0.6094],\n",
      "        [ 0.7656, -0.1094, -0.6875, -0.6562],\n",
      "        [ 0.3281, -0.2656, -0.5938, -0.5625],\n",
      "        [ 0.9375,  0.0000, -0.8750, -0.3906]])\n",
      "left: 1316 / 2531\n",
      "right: 1366 / 2531\n",
      "front: 1142 / 2531\n",
      "behind: 1462 / 2531\n",
      "above: 0 / 269\n",
      "below: 0 / 269\n",
      "acc_left: 0.519952587909917\n",
      "acc_right: 0.5397076254444884\n",
      "acc_front: 0.45120505728960886\n",
      "acc_behind: 0.5776372975108652\n",
      "acc_above: 0.0\n",
      "acc_below: 0.0\n",
      "avg_acc: 0.5221256420387199\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>█▃▄▁▁</td></tr><tr><td>acc_above</td><td>▁█▁▁▁</td></tr><tr><td>acc_behind</td><td>▃█▄▁▃</td></tr><tr><td>acc_below</td><td>▁▁▁▁▁</td></tr><tr><td>acc_front</td><td>█▁▇▄▇</td></tr><tr><td>acc_left</td><td>█▄▃▂▁</td></tr><tr><td>acc_right</td><td>█▄▃▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>0.52213</td></tr><tr><td>acc_above</td><td>0.0</td></tr><tr><td>acc_behind</td><td>0.57764</td></tr><tr><td>acc_below</td><td>0.0</td></tr><tr><td>acc_front</td><td>0.45121</td></tr><tr><td>acc_left</td><td>0.51995</td></tr><tr><td>acc_right</td><td>0.53971</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">LayoutGPT_3</strong> at: <a href='https://wandb.ai/xingjian-bai/diffusion_bbox_eval/runs/wcpfyapl' target=\"_blank\">https://wandb.ai/xingjian-bai/diffusion_bbox_eval/runs/wcpfyapl</a><br/>Synced 7 W&B file(s), 500 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230720_111519-wcpfyapl/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# wandb_drawer = None\n",
    "wandb_drawer = wandb.init(\n",
    "            project=\"diffusion_bbox_eval\",\n",
    "            name=f\"LayoutGPT_3\",\n",
    "            save_code=True)\n",
    "evaluate(result2, 2, wandb_drawer)\n",
    "evaluate(result3, 3, wandb_drawer)\n",
    "evaluate(result4, 4, wandb_drawer)\n",
    "evaluate(result5, 5, wandb_drawer)\n",
    "evaluate(result8, 8, wandb_drawer)\n",
    "if wandb_drawer is not None:\n",
    "    wandb_drawer.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
