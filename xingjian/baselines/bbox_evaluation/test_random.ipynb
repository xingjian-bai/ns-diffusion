{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/viscam/projects/ns-diffusion/xingjian/miniconda3/envs/diffusion/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import random\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import wandb\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from dataset_clevr_ryan import RelationalDataset, BoundingBox\n",
    "from utils import *\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from einops import rearrange, reduce\n",
    "from einops.layers.torch import Rearrange\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../bbox_classifier')\n",
    "from classifier import BboxClassifier\n",
    "from eval_pipeline import *\n",
    "metric_model = BboxClassifier()\n",
    "metric_model.load_state_dict(torch.load('../bbox_classifier/4-layer-DNN-48_multi_rels-100.pth'))\n",
    "def single_image_eval(bboxes, relations, relations_ids, eval_info = EvalInfo()):\n",
    "    bboxes.double()\n",
    "    relations.double()\n",
    "    relations_ids.double()\n",
    "    # print(\"entered single image eval\")\n",
    "    correct_relations = 0\n",
    "    for (i, rel) in enumerate(relations):\n",
    "        (a, b) = relations_ids[i]\n",
    "        a = a.item()\n",
    "        b = b.item()\n",
    "        # print(\"?\", bboxes[a],bboxes[b], rel)\n",
    "        rel_id = rel[-1]\n",
    "        input = torch.concat([bboxes[a].cuda(), bboxes[b].cuda(), torch.tensor([rel_id]).cuda()])\n",
    "        input = input.cuda().double()\n",
    "        metric_model.cuda().double()\n",
    "        pred = metric_model(input)[0].item()\n",
    "        correct_relations += pred > 0.5\n",
    "        eval_info.update(rel_id, pred > 0.5)\n",
    "\n",
    "        # print(f\"{i}th relation: {pred} vs {rel[0]}\")\n",
    "    return correct_relations / len(relations), eval_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(data, obj_num, wandb_drawer = None, no_above_below = True):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    metric_model.to(device)\n",
    "    metric_model.eval()\n",
    "    all_gen_bboxes, all_relations, all_relation_ids = data\n",
    "\n",
    "    size = len(all_gen_bboxes)\n",
    "    # assert size == 100\n",
    "\n",
    "    eval_info = EvalInfo()\n",
    "    scores = []\n",
    "\n",
    "    for i in range(size):\n",
    "        bboxes = all_gen_bboxes[i]\n",
    "        relations = all_relations[i]\n",
    "        relations_ids = all_relation_ids[i]\n",
    "        # if i == 0:\n",
    "        #     print(\"sample bboxes\", bboxes)\n",
    "        score, eval_info = single_image_eval(bboxes, relations, relations_ids, eval_info)\n",
    "        scores.append(score)\n",
    "    \n",
    "    bboxes = [[BoundingBox(e.tolist()) for e in bboxes] for bboxes in all_gen_bboxes]\n",
    "\n",
    "    images = [None] * 8\n",
    "    for i in range(8):\n",
    "        image = Image.new('RGB', (256, 256), (255, 255, 255))\n",
    "        colours = [(255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 0), (0, 255, 255), (255, 0, 255)] # red, green, blue, yellow, cyan, magenta\n",
    "        for j, bbox in enumerate(bboxes[i]):\n",
    "            image = bbox.draw(image, color=colours[j % len(colours)])\n",
    "        images[i] = image\n",
    "    if wandb_drawer is not None:\n",
    "        wandb_drawer.log({\"images\": [wandb.Image(image) for image in images]}, step = obj_num)\n",
    "    # save images to file\n",
    "    for i in range(8):\n",
    "        images[i].save(f\"images/Random_{obj_num}_{i}.png\")\n",
    "\n",
    "    if no_above_below:\n",
    "        avg_score = (eval_info.correct_relations[0] + eval_info.correct_relations[1] + eval_info.correct_relations[2] + eval_info.correct_relations[3]) / (eval_info.total_relations[0] + eval_info.total_relations[1] + eval_info.total_relations[2] + eval_info.total_relations[3])\n",
    "    else:\n",
    "        avg_score = sum(scores) / len(scores)\n",
    "    \n",
    "\n",
    "    # separately log each relation's acc\n",
    "    eval_info_list = eval_info.to_list()\n",
    "    eval_info.print()\n",
    "    for i in range(6):\n",
    "        print(f\"acc_{eval_info.relation_names[i]}: {eval_info_list[i]}\")\n",
    "        if wandb_drawer is not None:\n",
    "            wandb_drawer.log({f\"acc_{eval_info.relation_names[i]}\": eval_info_list[i]}, step = obj_num)\n",
    "    print(f\"avg_acc: {avg_score}\")\n",
    "    if wandb_drawer is not None:\n",
    "        wandb_drawer.log({\"acc\": avg_score}, step = obj_num)\n",
    "    return avg_score\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:12l7gvq2) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">random</strong> at: <a href='https://wandb.ai/xingjian-bai/diffusion_bbox_eval/runs/12l7gvq2' target=\"_blank\">https://wandb.ai/xingjian-bai/diffusion_bbox_eval/runs/12l7gvq2</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230720_001151-12l7gvq2/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:12l7gvq2). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/viscam/projects/ns-diffusion/xingjian/baselines/cfg_bbox7_cleanup/wandb/run-20230720_001223-w0569gzw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/xingjian-bai/diffusion_bbox_eval/runs/w0569gzw' target=\"_blank\">random</a></strong> to <a href='https://wandb.ai/xingjian-bai/diffusion_bbox_eval' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/xingjian-bai/diffusion_bbox_eval' target=\"_blank\">https://wandb.ai/xingjian-bai/diffusion_bbox_eval</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/xingjian-bai/diffusion_bbox_eval/runs/w0569gzw' target=\"_blank\">https://wandb.ai/xingjian-bai/diffusion_bbox_eval/runs/w0569gzw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/viscam/projects/ns-diffusion/xingjian/baselines/cfg_bbox7_cleanup/../dataset.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(self.pos)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left: 394 / 736\n",
      "right: 180 / 736\n",
      "front: 260 / 733\n",
      "behind: 444 / 733\n",
      "above: 0 / 0\n",
      "below: 0 / 0\n",
      "acc_left: 0.5353260869565217\n",
      "acc_right: 0.24456521739130435\n",
      "acc_front: 0.35470668485675305\n",
      "acc_behind: 0.6057298772169167\n",
      "acc_above: 0\n",
      "acc_below: 0\n",
      "avg_acc: 0.43498978897208984\n",
      "Empty images\n",
      "left: 1180 / 2152\n",
      "right: 543 / 2152\n",
      "front: 711 / 2164\n",
      "behind: 1278 / 2164\n",
      "above: 0 / 0\n",
      "below: 0 / 0\n",
      "acc_left: 0.5483271375464684\n",
      "acc_right: 0.25232342007434944\n",
      "acc_front: 0.3285582255083179\n",
      "acc_behind: 0.5905730129390019\n",
      "acc_above: 0\n",
      "acc_below: 0\n",
      "avg_acc: 0.43002780352177944\n",
      "Empty images\n",
      "left: 2391 / 4338\n",
      "right: 1038 / 4338\n",
      "front: 1495 / 4346\n",
      "behind: 2612 / 4346\n",
      "above: 0 / 0\n",
      "below: 0 / 0\n",
      "acc_left: 0.5511756569847857\n",
      "acc_right: 0.2392807745504841\n",
      "acc_front: 0.34399447768062585\n",
      "acc_behind: 0.6010124252185918\n",
      "acc_above: 0\n",
      "acc_below: 0\n",
      "avg_acc: 0.43390142791340397\n",
      "Empty images\n",
      "left: 3988 / 7236\n",
      "right: 1844 / 7236\n",
      "front: 2535 / 7175\n",
      "behind: 4357 / 7175\n",
      "above: 0 / 0\n",
      "below: 0 / 0\n",
      "acc_left: 0.5511332227750139\n",
      "acc_right: 0.25483692647871753\n",
      "acc_front: 0.3533101045296167\n",
      "acc_behind: 0.6072473867595819\n",
      "acc_above: 0\n",
      "acc_below: 0\n",
      "avg_acc: 0.44146832280896536\n",
      "Empty images\n"
     ]
    }
   ],
   "source": [
    "\n",
    "wandb_drawer = None\n",
    "wandb_drawer = wandb.init(\n",
    "            project=\"diffusion_bbox_eval\",\n",
    "            name=f\"random\",\n",
    "            save_code=True)\n",
    "for obj_num in [2,3,4,5,6,7,8,9]:\n",
    "    dataset = RelationalDatasetxO(obj_num, upperbound = 1000)\n",
    "\n",
    "    bboxes = []\n",
    "    relations = []\n",
    "    relations_ids = []\n",
    "\n",
    "    for i in range(len(dataset)):\n",
    "        clean_image, objects, rels, bbes, generated_prompt, raw_image, raw_image_tensor, rels_ids = dataset[i]\n",
    "        bboxes.append(bbes)\n",
    "        relations.append(rels)\n",
    "        relations_ids.append(rels_ids)\n",
    "\n",
    "    data = (bboxes, relations, relations_ids)\n",
    "    evaluate(data, obj_num, wandb_drawer = wandb_drawer)\n",
    "    \n",
    "if wandb_drawer is not None:\n",
    "    wandb_drawer.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
